# CausalStress Sensitivity Analysis

**Status:** Deferred (Post-MVP)  
**Version:** Draft  
**Date:** 2025-05-26

---

## 4.6 Sensitivity Analysis (Kill Curves & Efficiency Curves)

Sensitivity Analysis provides systematic stress-testing of estimators by sweeping one or more DGP parameters across controlled ranges.

This functionality enables users to quantify:

- Finite-sample efficiency (data starvation)
- Robustness to structural corruption (stress tests)
- Breakdown points (parameter values where estimators fail)
- Variance explosion (bootstrap CI instability)
- Practical minimum sample size (coverage recovery)

CausalStress implements sensitivity analysis as a thin wrapper around `cs_run_design()`, ensuring full bootstrap support, parallel safety, and complete provenance capture.

---

## 4.6.1 API: `cs_run_sensitivity()`

```r
cs_run_sensitivity <- function(
  dgp_id,
  estimator_ids,
  param_name,
  param_values,
  n_rep       = 100,
  N           = NULL,
  tau         = seq(0.05, 0.95, 0.05),
  bootstrap   = TRUE,
  B           = 200,
  parallel    = TRUE,
  config      = list(),
  board       = NULL
)
```

**Purpose:**

Runs repeated experiments while varying one DGP parameter. Maintains all runner semantics:

- DGP generation (via `cs_run_single`)
- Estimation
- Bootstrapping
- Full truth-based metric computation
- Pins integration

**Inputs:**

| Argument | Type | Description |
|----------|------|-------------|
| `dgp_id` | string | DGP to sweep |
| `estimator_ids` | character vector | Estimators to compare |
| `param_name` | string | Name of the DGP parameter to vary (e.g., "N", "tilt", "outlier_scale") |
| `param_values` | vector | Values to sweep over |
| `n_rep` | int | Repetitions per parameter value |
| `N` | int or NULL | Optional override for sample size |
| `tau` | numeric vector | QST quantile grid |
| `bootstrap` | logical | Whether to run bootstrap CIs |
| `B` | int | Number of bootstrap replicates |
| `parallel` | logical | Whether to use outer-level parallelism |
| `config` | list | Estimator config |
| `board` | pins board | Optional artifact storage |

---

## 4.6.2 Contract: What DGPs Must Support

A DGP used in sensitivity analysis must:

1. Accept the parameter being varied:

```r
dgp_fn <- function(N = 2000, outlier_scale = 1, tilt = 0, ...)
```

2. Include these in `meta$params`

3. Not break when parameters are extreme (return NA instead of errors)

---

## 4.6.3 Internal Mechanics

**Design Construction:**

`cs_run_sensitivity()` produces a tidy tibble design:

```r
design <- tidyr::crossing(
  estimator_id = estimator_ids,
  param_value  = param_values,
  rep          = seq_len(n_rep)
) %>%
  mutate(
    seed         = rep + 1000L * match(param_value, param_values),
    dgp_id       = dgp_id,
    dgp_params   = map(param_value, ~ setNames(list(.x), param_name)),
    N            = N %||% NULL,
    bootstrap    = bootstrap,
    B            = B
  )
```

Then hands this to:

```r
cs_run_design(design, parallel = parallel, config = config, board = board)
```

Because all runners exclusively call `cs_run_single()`, sensitivity sweeps automatically inherit:

- Bootstrap support
- Bias metrics
- Coverage
- CI widths
- Estimator metadata
- DGP metadata
- Pins writing
- Bootstrap failure handling

---

## 4.6.4 Output Structure

`cs_run_sensitivity()` returns:

```r
list(
  results         = sensitivity_raw,
  summary_att     = att_summary,
  summary_qst     = qst_summary,
  param_name      = param_name,
  param_values    = param_values,
  estimators      = estimator_ids,
  dgp_id          = dgp_id,
  n_rep           = n_rep,
  bootstrap       = bootstrap,
  B               = B,
  timestamp       = Sys.time()
)
```

**Per-run metrics** (auto-generated by `cs_run_single`):

- `att$bias`, `att$covered`, `att$ci_width`
- `qst$bias`, `qst$covered`, `qst$ci_width`

**Aggregated summaries:**

**ATT Summary** — One row per estimator × param_value:

| param_value | estimator_id | mean_bias | rmse | coverage | mean_ci_width |
|-------------|--------------|-----------|------|----------|---------------|

**QST Summary** — One row per estimator × param_value × τ:

| param_value | estimator_id | tau | mean_bias | mean_abs_bias | coverage |
|-------------|--------------|-----|-----------|---------------|----------|

---

## 4.6.5 Protocol A: Data Starvation (Efficiency Curves)

**Goal:** Evaluate finite-sample behavior.

**Preset Sweep:**

```r
param_name   = "N"
param_values = c(100, 250, 500, 1000, 2000, 5000, 10000)
```

**Expected Patterns:**

- **AIPW (correctly specified):** RMSE ∝ N^{-½}, coverage → 0.95
- **GRF/GenGC:** slower early convergence; stabilizes as forests get enough samples
- **Breakdown:** when N is small, splits fail → bias spikes, coverage collapses

**Metrics of interest:**

- Convergence rate α from: RMSE ∝ N^{-α}
- Minimum viable N: smallest N with coverage ≥ 0.9

---

## 4.6.6 Protocol B: Structural Stress (Robustness Curves)

**Goal:** Quantify robustness as the DGP introduces corruption.

**Common knobs:**

| DGP | Parameter | Meaning | Typical Range |
|-----|-----------|---------|---------------|
| `synth_heavytail` | `outlier_scale` | Cauchy dispersion | 1 → 50 |
| `synth_overlap_stressed` | `tilt` | Propensity distortion | 0 → 5 |
| `synth_qte1` | `heterogeneity_amp` | QST S-curve amplitude | 0 → 5 |

**Breakdown Definitions:**

- **Bias Breakdown:** When `abs(mean_bias) > δ × |true_effect|` (δ = 0.20 by default)
- **Variance Explosion:** When CI width > 10× baseline
- **Noncoverage:** Coverage < 0.5 or → 0

---

## 4.6.7 Visualization: `cs_plot_kill_curve()`

```r
cs_plot_kill_curve(
  sensitivity_results,
  y_metric       = "rmse",
  show_breakdown = TRUE,
  log_x          = (param_name == "N")
)
```

**Chart Features:**

- X-axis: sweep parameter
- Y-axis: estimator performance (RMSE, bias, coverage, etc.)
- Lines: estimators
- Ribbons: Monte Carlo standard error
- Vertical lines: breakdown thresholds
- Log–log scaling: automatically applied for N-sweeps

**Interpretation:**

- Early divergence: low robustness
- Flat response: high robustness
- Delayed convergence: sample-inefficient
- Variance cliffs: bootstrap instability

---

## 4.6.8 Pins Integration

If a board is provided:

**Granular pins** (per parameter × estimator × seed):

```
sensitivity/{dgp_id}_v{version}/{estimator_id}_v{version}/{param_name}/{value}/seed_{seed}
```

**Summary pin:**

```
sensitivity_summary/{dgp_id}/{param_name}/{timestamp}
```

Includes:

- Full parameter grid
- ATT summary
- QST summary
- Bootstrap statistics
- Full provenance

---

## 4.6.9 Failure Semantics

- If an estimator errors on a replicate → a row with `success = FALSE`, metrics = NA
- If >50% reps for a parameter value fail → summary row flagged
- Bootstrap failures are captured via `n_boot_ok`, `meta$errors`, `meta$warnings`

Thus no sweep ever crashes the entire run.

---

## 4.6.10 Why This Design Is Powerful

- **Plug-and-play:** any estimator, any DGP knob
- **Automatically bootstrap-aware**
- **Automatically truth-aware** for synthetic DGPs
- **Parallel-safe** (inherits the single-thread estimator rule)
- **Pins-friendly**
- **Future-proof:** easy to extend to multi-parameter sweeps

This gives CausalStress the same feel as:

- ML stress testing
- Econometric sensitivity analysis
- Reliability engineering kill curves
- Adversarial benchmarking frameworks
