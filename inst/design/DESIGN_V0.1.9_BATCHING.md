# Design Document: CausalStress v0.1.9 (Scalable Batching)

Status: Frozen

Target Version: v0.1.9

Focus: High-Throughput Architecture, File System Hygiene, Deterministic Scheduling

## 1. Objective

To enable campaign-scale simulations (100,000+ runs) by moving from "One File Per Run" to "One File Per Batch" (Aggregate Storage).

## 2. Core Architecture: "Staging & Commit"

### 2.1 The Workflow

1.  **Plan:** Coordinator generates a **Global Cartesian Shuffle** map.

2.  **Compute:** Worker runs a batch in a loop, writing one atomic `.qs` file to `staging/`.

    -   *Constraint:* Workers **never** touch `pins`.

3.  **Commit:** Coordinator scans `staging/` and promotes valid batches to `pins` storage.

## 3. Data Structures

### 3.1 The Flight Plan (The Map)

A tibble generated by `cs_plan_campaign`.

R

```         
tibble(   batch_id = 1:2000,   # The "Manifest" for this batch   tasks = list(     tibble(       dgp_id = "...",        estimator_id = "...",        seed = 12345,       # Strategy Map Integration:       task_config = list(          n_boot = 500,          ci_method = "percentile", # Resolved from defaults + overrides          ...       ),       resolved_config_hash = "...", # Hash of resolved task_config       task_fingerprint = "...",    # Hash(dgp + est + seed + task_config)       fingerprint_version = 2,     # Schema version for the hash logic       config_fingerprint_schema = 2 # Schema version for config fingerprints     )   ) ) 
```

### 3.1.1 Config Resolution (Strategy Map)

Each task must carry a resolved config, derived deterministically from:

-   defaults (global config)

-   overrides[estimator_id] (estimator-specific)

Rules:

1.  Start with defaults.

2.  If overrides[estimator_id] exists, overlay using modifyList.

3.  The resolved config is used for fingerprinting and execution.

Fields to include in task rows:

-   resolved_config_hash (fingerprint of resolved config)

-   config_fingerprint_schema (version)

### 3.2 The Batch Artifact (The Payload)

Saved as `batch_{id}.qs`.

R

```         
list(   schema_version = "v1.0.0",  # Batch Schema Version      # 1. Batch Provenance   meta = list(     batch_id = 42,     timestamp = "...",     node_info = list(sysname = "Linux", nodename = "compute-01"),     session_info = "...",          git_hash = "..."   ),      # 2. Scientific Results   results = list(     # List of Result Objects. Each MUST contain:     # - att: { ... }     # - qst: { ..., tau_id: "0.5" }  <-- EXPLICIT REQUIREMENT     # - meta: { ... } (Task-level provenance)   ),      # 3. Structured Error Log   errors = list(     tibble(       seed = 12345,       dgp_id = "...",       estimator_id = "...",       message = "Singular matrix inversion...",       traceback = "...",       timestamp = "..."     )   ) ) 
```         

Extend the schema:

-   results must include:

    -   task_fingerprint

    -   config_fingerprint_schema

    -   tau_id (if qst is present)

-   errors must be structured:

    -   list(seed, dgp_id, estimator_id, task_fingerprint, error_class, message, traceback, timestamp)

## 4. Component Specifications

### 4.1 `cs_plan_campaign` (The Architect)

-   **Algorithm:**

    1.  Generate full grid (DGP $\times$ Est $\times$ Seed).

    2.  **Strategy Resolution:** For each row, resolve the final config (defaults + strategy map overrides) *before* execution.

    3.  **Global Cartesian Shuffle:** `set.seed(campaign_seed); grid <- grid[sample(nrow(grid)), ]`.

    4.  Chunk into `batch_id`.

### 4.2 `cs_run_batch` (The Worker)

-   **Input:** `batch_id`, `plan`, `staging_dir`.

-   **The Loop:**

    1.  **Governance:** `cs_set_rng(task$seed)` + `cs_enforce_threads(1)` + fail-closed registry checks.

    2.  **Execution:** Run simulation using `task$task_config`.

    3.  **Error Handling:** Catch errors, log to `errors` tibble, **continue** to next seed.

-   **Atomic Write:** Save to `staging/batch_{id}_{uuid}.qs`.

### 4.3 `cs_consolidate` (The Librarian)

-   **Input:** `staging_dir`, `board`.

-   **Logic:**

    1.  Validate `schema_version`, integrity, and required fields (task_fingerprint, config_fingerprint_schema, tau_id when qst present).

    2.  **Idempotency:** If `batch_id` exists in board, SKIP.

    3.  **Pin:** Write to `board` with metadata `type="batch"`.

## 5. Backward Compatibility (Legacy Bridge)

The system must handle boards containing both v0.1.8 (single) and v0.1.9 (batch) pins.

-   **Detection:** `cs_audit` must check `pin_meta$type` (or infer from filename/structure).

-   **Adaptation:**

    -   If `type == "single"`: Read 1 file $\to$ 1 row.

    -   If `type == "batch"`: Read 1 file $\to$ Expand `results` list $\to$ N rows.

Accessors must propagate task_fingerprint and config_fingerprint_schema into tidy rows.

## 6. Testing Strategy

1.  **Determinism:** `cs_plan_campaign(seed=1)` must produce identical batch assignments every time.

2.  **Resume Logic:** Mock a board with Batch 1 present. Run plan. Ensure Batch 1 is excluded from Todo list.

3.  **Error Schema:** Force an estimator error. Verify `batch$errors` contains the structured log.

4.  **Schema Validation:** Reject batch artifacts missing task_fingerprint or config_fingerprint_schema.

5.  **Legacy Compatibility:** Boards containing v0.1.8 pins and v0.1.9 batch pins must load via `cs_audit` and `cs_tidy` without errors.

### **Action 2: The Ticket Breakdown**

Here are the Tickets to execute this plan.

**Ticket 7: The Planner (`cs_plan_campaign`)**

-   **Goal:** Implement the "Flight Plan" logic.

-   **Tasks:**

    -   Create `cs_plan_campaign` function.

    -   Implement Cartesian Product + Strategy Map Resolution.

    -   Implement Global Shuffle (seeded).

    -   Implement Chunking.

    -   **Test:** Verify determinism and strategy map overrides.

**Ticket 8: The Worker (`cs_run_batch`)**

-   **Goal:** Implement the execution loop.

-   **Tasks:**

    -   Create `cs_run_batch`.

    -   Implement the loop with `cs_set_rng` and `cs_enforce_threads`.

    -   Implement Try-Catch-Log logic (the Error Schema).

    -   Implement Atomic Staging Write (`.qs`).

    -   **Test:** Run a batch where 1 seed fails and 1 succeeds. Check artifact structure.

**Ticket 9: The Aggregator (`cs_consolidate` & Accessors)**

-   **Goal:** Storage management and Analysis.

-   **Tasks:**

    -   Create `cs_consolidate` (Staging $\to$ Pins).

    -   Update `cs_audit` to handle "Batch" pins (Legacy Bridge).

    -   Update `cs_tidy` to unpack lists-of-lists.

    -   **Test:** End-to-End: Plan $\to$ Run $\to$ Consolidate $\to$ Tidy.
